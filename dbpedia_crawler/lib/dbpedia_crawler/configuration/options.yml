crawler:
  check_types: false                          # whether to validate the type of crawled movies and shows
  crawl_all_ids: true                         # whether to push the initial command on start
  command_retries: 1                          # number of retries for failed commands
  insomnia: true                              # when there is no command left, push the "crawl ids" command again
  sleep_seconds: 5                            # seconds to sleep if command queue is empty

queue:
  agent_id: "dbpedia"                         # identifier of this crawler (to determine the queues)
  purge: true                                 # whether to purge the queue on start
  purge_retries: 5                            # retries if purge raises exception for very large queue
  purge_sleep_seconds: 10                     # how long to sleep before attempting another purge
  queue: "lom.source"                         # first part of the queues (full name e.g.: "lom.source.dbpedia.movie")

source:
  endpoint: "http://dbpedia.org/sparql"       # URI of the SPARQL endpoint
  page_size: 10000                            # number of entities queried at a time, <= 50,000 (Ruby.rdf limit)
  query_retries: 5                            # number of retries for failed data retrieval

type_checker:
  threshold: 20                               # threshold in percent

writer:
  batch_size: 1000                            # number of triples inserted at a time (do not know maximum, use <= 1000)
  endpoint: "http://localhost:8890/sparql"    # URI of the SPARQL endpoint
  graph: "http://example.com/raw/"            # named graph for storing data
